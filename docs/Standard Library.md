# **GXO Standard Library (GXO-SL) Reference**

**Document ID:** GXO-SL-V1
**Version:** 1.0
**Status:** Canonical Module Specification

## Table of Contents
- [1. Introduction: The GXO Automation Model (GXO-AM)](#1-introduction-the-gxo-automation-model-gxo-am)
  - [1.1. The GXO-AM Framework](#11-the-gxo-am-framework)
  - [1.2. Design Philosophy](#12-design-philosophy)
- [2. Layer 0: The Kernel](#2-layer-0-the-kernel)
- [Layer 1: System Layer](#layer-1-system-layer)
  - [`exec`](#exec)
  - [`filesystem:read`](#filesystemread)
  - [`filesystem:write`](#filesystemwrite)
  - [`filesystem:stat`](#filesystemstat)
  - [`filesystem:list`](#filesystemlist)
  - [`filesystem:manage`](#filesystemmanage)
  - [`control:wait_for_signal`](#controlwait_for_signal)
  - [`control:barrier`](#controlbarrier)
  - [`control:assert`](#controlassert)
  - [`control:identity`](#controlidentity)
- [Layer 2: Connection Layer](#layer-2-connection-layer)
  - [`connection:open`](#connectionopen)
  - [`connection:listen`](#connectionlisten)
  - [`connection:read`](#connectionread)
  - [`connection:write`](#connectionwrite)
  - [`connection:close`](#connectionclose)
- [Layer 3: Protocol Layer](#layer-3-protocol-layer)
  - [`dns:query`](#dnsquery)
  - [`http:listen`](#httplisten)
  - [`http:respond`](#httprespond)
  - [`ssh:connect`](#sshconnect)
  - [`ssh:command`](#sshcommand)
  - [`ssh:script`](#sshscript)
- [Layer 4: Data Plane](#layer-4-data-plane)
  - [`data:parse`](#dataparse)
  - [`data:map`](#datamap)
  - [`data:filter`](#datafilter)
  - [`data:join`](#datajoin)
  - [`data:aggregate`](#dataaggregate)
  - [`data:format`](#dataformat)
  - [`passthrough`](#passthrough)
- [Layer 5: Application Layer](#layer-5-application-layer)
  - [`http:request`](#httprequest)
  - [`database:query`](#databasequery)
- [Layer 6: Integration Layer](#layer-6-integration-layer)
  - [`artifact:*` Suite](#artifact-suite)
  - [`terraform:run`](#terraformrun)
  - [Notification Suite (`slack:post_message`, `email:send`, etc.)](#notification-suite-slackpost_message-emailsend-etc)
- [Appendix A: GXO-SL Complete Module Checklist](#appendix-a-gxo-sl-complete-module-checklist)
  - [Layer 1: System Layer](#layer-1-system-layer-1)
  - [Layer 2: Connection Layer](#layer-2-connection-layer-1)
  - [Layer 3: Protocol Layer](#layer-3-protocol-layer-1)
  - [Layer 4: Data Plane (ETL Services)](#layer-4-data-plane-etl-services)
  - [Layer 5: Application Layer](#layer-5-application-layer-1)
  - [Layer 6: Integration Layer](#layer-6-integration-layer-1)

## **1. Introduction: The GXO Automation Model (GXO-AM)**

The GXO Standard Library (GXO-SL) is the foundational "standard library" of the GXO Automation Kernel. It is an exhaustive, built-in suite of performant, reliable, and highly composable modules designed to function as the "system calls" and "standard libraries" of an automation-centric operating system.

### **1.1. The GXO-AM Framework**

The design of the GXO-SL is governed by the **GXO Automation Model (GXO-AM)**, a layered architecture where each layer provides a specific class of service, building upon the primitives offered by the layer below it. This ensures a logical, consistent, and highly composable system, preventing monolithic modules and promoting maximum code reuse.

The GXO-AM is intentionally designed as a conceptual parallel to the **OSI model** for computer networking. Just as the GXO engine itself is architected as an **Automation Kernel** (analogous to an OS microkernel), its module system provides a corresponding layered model for automation services. This structure allows users to operate at the highest level of abstraction for convenience (e.g., the "Application Layer" `http:request` module) or drop down to lower layers for granular control and custom protocol implementation (e.g., the "Connection Layer" `connection:*` modules). This document provides the complete, detailed function and specification of every module within this layered model.

### **1.2. Design Philosophy**

*   **Primitives over Frameworks:** Each module offers a discrete, self-contained capability, giving the user maximum control and flexibility. A module does one thing and does it well.
*   **Composability by Design:** Complex workflows are constructed by connecting modules across layers via GXO's native state management (`register`) and streaming data flow (`stream_inputs`), with parameters dynamically generated by powerful template functions.
*   **Security by Default:** Modules operate with the least privilege necessary. They must handle sensitive data securely and are expected to be good citizens within the GXO security model (respecting `DryRun` contexts, validating parameters, etc.).
*   **Consistency and Clarity:** Modules adhere to a consistent `namespace:action` naming scheme (e.g., `filesystem:read`, `connection:open`). Parameters and summary structures are predictable across the library.
*   **Explicit Lifecycle Support:** Every module's specification explicitly declares which `Lifecycle` policies it supports (e.g., `run_once`, `supervise`). A module designed for a one-shot task cannot be used in a `supervise` lifecycle unless it is explicitly designed to be a long-running process.

## **2. Layer 0: The Kernel**

The GXO-AM rests on Layer 0: the **GXO Automation Kernel** itself. This is the `gxo` binaryâ€”the engine that provides the core services of scheduling, dependency management (DAG), state management, streaming data flow, and secure `Workspace` management. It is the "hardware and operating system" upon which all modules (the "software") run. The modules detailed below are the programs that execute on this Kernel.

---

## **Layer 1: System Layer**

**Analogy:** The "Bare Metal" of automation.
**Purpose:** Provides direct, un-abstracted access to the host operating system's most fundamental resources: its processes and its filesystem. This layer is the bedrock of system-level configuration, local command execution, and interaction with the Kernel's control flow.

### `exec`
*   **Synopsis:** Executes local system commands and scripts.
*   **Description:** This is the most fundamental building block for interacting with any binary or script on the host system where the GXO Kernel is running. The `exec` module runs a command as a child process of the GXO Kernel. It captures the complete standard output (`stdout`), standard error (`stderr`), and the final exit code of the command. This captured information is returned as a structured map in the `summary`, making it immediately available to downstream `Workloads` for parsing or conditional logic. The command is executed within the `Workload`'s `Workspace`. It fully respects context cancellation, meaning a long-running command will be terminated if the playbook is cancelled or times out.
*   **Supported Lifecycles:** `run_once`, `supervise`
*   **Parameters:**
    | Name | Type | Required? | Default | Description |
    |---|---|---|---|---|
    | `command` | string | Yes | | The command, binary, or script to execute. Must be an absolute path or a command name present in the GXO process's `PATH`. |
    | `args` | list[string] | No | `[]` | A list of string arguments to pass to the command. Each element in the list is a separate argument. |
    | `environment`| list[string]| No | `[]` | A list of `KEY=VALUE` strings to set as the command's environment. **Important:** If provided, this *replaces* the GXO Kernel's environment entirely for this specific command; it does not append to it. |
*   **Notes:**
    *   This module is powerful but should be used with caution, as it can execute any command with the permissions of the GXO Kernel process. For production, the daemon should run as a least-privileged user.
    *   When used in a `supervise` lifecycle, this module allows GXO to act as a simple process supervisor for any application.
*   **Return Values / Summary:**
    A map containing the following keys:
    | Key | Type | Description |
    |---|---|---|
    | `stdout` | string | The captured standard output of the command as a single string. |
    | `stderr` | string | The captured standard error of the command as a single string. |
    | `exit_code` | int | The integer exit code of the command. `0` typically indicates success. |
*   **Examples:**
    ```yaml
    # Example 1: Get the kernel version
    process:
      module: exec
      params:
        command: "uname"
        args: ["-r"]
    register: kernel_version

    # Example 2: Run a shell script with a specific environment
    process:
      module: exec
      params:
        command: "/bin/bash"
        args: ["./scripts/deploy.sh"]
        environment:
          - "APP_ENV=production"
          - "DB_HOST=prod.db.internal"
    ```

### `filesystem:read`
*   **Synopsis:** Reads the content of a file.
*   **Description:** This module is used for reading configuration files, small data files, scripts, or any other text-based content from the local filesystem. It reads the entire file into a single string in the `summary`. It is designed for convenience with reasonably sized files. For very large files (hundreds of megabytes or gigabytes), using a streaming approach with other modules may be more memory-efficient. All paths are resolved relative to the `Workload`'s `Workspace`, preventing path traversal attacks.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `path` | string | Yes | The path to the file to be read, relative to the `Workspace`. |
*   **Return Values / Summary:**
    | Key | Type | Description |
    |---|---|---|
    | `content` | string | The entire content of the file as a single UTF-8 string. |
*   **Examples:**
    ```yaml
    process:
      module: filesystem:read
      params:
        path: "config/app.json"
    register: app_config_json
    ```

### `filesystem:write`
*   **Synopsis:** Writes content to a file.
*   **Description:** Creates a new file, overwrites an existing file, or appends to an existing file with the provided content. It is a fundamental tool for generating configuration files, reports, or any script output. The module will automatically create parent directories if they do not exist. All paths are resolved relative to the `Workspace`.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Default | Description |
    |---|---|---|---|---|
    | `path` | string | Yes | | The path to the file to be written, relative to the `Workspace`. |
    | `content` | string | Yes | | The string content to write to the file. |
    | `mode` | string | No | `"0644"` | The file permissions in octal format (e.g., `"0644"`, `"0755"`). |
    | `append` | bool | No | `false` | If `true`, appends content to the end of the file instead of overwriting. |
*   **Return Values / Summary:**
    | Key | Type | Description |
    |---|---|---|
    | `path` | string | The absolute path of the file that was written. |
    | `bytes_written` | int | The number of bytes written to the file. |
*   **Examples:**
    ```yaml
    process:
      module: filesystem:write
      params:
        path: "output/report.txt"
        content: "System check completed at {{ now }}."
        mode: "0600"
    ```

### `filesystem:stat`
*   **Synopsis:** Gathers metadata about a file or directory.
*   **Description:** This module acts like the `stat` command-line utility. It inspects a path and returns a structured map containing its properties, such as size, permissions, type (file or directory), and modification time, without reading its content. This is useful for checks and conditional logic before performing other filesystem operations. It will fail if the path does not exist.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `path` | string | Yes | The path to the file or directory to inspect, relative to the `Workspace`. |
*   **Return Values / Summary:**
    | Key | Type | Description |
    |---|---|---|
    | `path` | string | The absolute path of the inspected item. |
    | `size` | int | The size of the file in bytes. For directories, this is OS-dependent. |
    | `mode` | string | The file permissions in octal format (e.g., "0755"). |
    | `is_dir` | bool | `true` if the path is a directory, `false` otherwise. |
    | `modified_time` | string | The last modification time in RFC3339 format. |
*   **Examples:**
    ```yaml
    process:
      module: filesystem:stat
      params:
        path: "artifacts/app.tar.gz"
    register: artifact_info
    ```

### `filesystem:list`
*   **Synopsis:** Lists the contents of a directory as a stream.
*   **Description:** This is the primary module for generating a file-based inventory for processing in a pipeline. It scans a directory and, for each item found (file or subdirectory), it emits one record onto its output stream. Each record has the exact same structure as the `summary` from the `filesystem:stat` module. This allows for powerful compositions, like listing all `.log` files and then feeding that stream to another `Workload` to read and parse them.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Default | Description |
    |---|---|---|---|---|
    | `path` | string | Yes | | The path to the directory to list, relative to the `Workspace`. |
    | `recursive` | bool | No | `false` | If `true`, lists directories and their contents recursively. |
    | `pattern` | string | No | `""` | An optional glob pattern (e.g., `*.log`, `config-??.yml`) to filter the results. |
*   **Output Stream:** A stream of records, where each record has the structure: `{ "path", "size", "mode", "is_dir", "modified_time" }`.

### `filesystem:manage`
*   **Synopsis:** Idempotently manages the state of files and directories.
*   **Description:** This is the core configuration management primitive for the filesystem. It ensures that a path on the filesystem matches a desired state. If the path is already in the desired state, it does nothing and reports `changed: false`. If not, it performs the necessary action (create, delete, chmod, chown) to bring it into the desired state and reports `changed: true`.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Choices | Description |
    |---|---|---|---|---|
    | `path` | string | Yes | | The path to manage, relative to the `Workspace`. |
    | `state` | string | Yes | `present`, `absent`, `directory` | Desired state: `"present"` (ensures file exists, like `touch`), `"absent"` (ensures path does not exist), `"directory"` (ensures path exists and is a directory). |
    | `owner` | string | No | | The username or UID to own the file/directory. Requires appropriate permissions. |
    | `group` | string | No | | The group name or GID to own the file/directory. Requires appropriate permissions. |
    | `mode` | string | No | | File permissions in octal format (e.g., `"0755"`). Applied if the state is changed. |
    | `recursive`| bool | No | `true`, `false` | If `state` is `"absent"`, recursively delete the directory and its contents. Defaults to `false`. |
*   **Return Values / Summary:**
    | Key | Type | Description |
    |---|---|---|
    | `path` | string | The absolute path of the managed item. |
    | `state` | string | The final state of the item. |
    | `changed` | bool | `true` if an action was taken, `false` otherwise. |

### `control:wait_for_signal`
*   **Synopsis:** Pauses a workflow and waits for an external resume signal.
*   **Description:** This is the core primitive for enabling human-in-the-loop workflows. When executed, it requests that the GXO Kernel pause the current workflow instance. The Kernel generates a unique, single-use token, persists the workflow's state, and returns the token in this module's `summary`. The workflow will not proceed until `gxo ctl resume --token <token>` is called. The payload from the `resume` command is injected back into the workflow's state for the next step.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `context` | map | No | An optional map of data to be stored with the paused state. This data can be queried by external systems to provide context to the human approver (e.g., via `gxo ctl get workflow <id>`). |
*   **Return Values / Summary:**
    | Key | Type | Description |
    |---|---|---|
    | `resume_token` | string | The unique, single-use token required to resume this workflow instance. |
*   **Examples:**
    ```yaml
    process:
      module: control:wait_for_signal
      params:
        context:
          user: "{{ .request_data.user }}"
          action: "Provision new virtual machine"
          cost: "{{ .cost_estimate.total }}"
    register: approval_handle
    ```

### `control:barrier`
*   **Synopsis:** A synchronization primitive that waits for multiple input streams to complete.
*   **Description:** This module is the core building block for creating stages in a CI/CD pipeline. It takes multiple `stream_inputs` and only completes successfully after it has received an "End-of-Stream" signal from *all* of them. It does not consume or process any records; it only waits for the channels to close. Its successful completion signals that all prerequisite `Workloads` in a stage are finished.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:** None.
*   **Streams:** Requires `stream_inputs`. Ignores all records on the streams.
*   **Return Values / Summary:** `{ "synchronized_streams": list[string] }` containing the names of the streams it waited for.
*   **Examples:**
    ```yaml
    # This workload acts as a barrier for Stage 2 of a pipeline.
    # It will only run after both 'build_backend' and 'build_frontend' are complete.
    process:
      module: control:barrier
      stream_inputs: [build_backend, build_frontend]
    ```

### `control:assert`
*   **Synopsis:** Fails a workload if a condition is not met.
*   **Description:** A core tool for validation and control flow. It evaluates a Go template expression. If the result is "truthy" (true, non-zero number, non-empty string), the module succeeds. If the result is "falsy" (false, 0, empty string, nil), the module returns a fatal error, failing the `Workload`. This can be used to validate the state of the system or the output of a previous `Workload`.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `condition` | string | Yes | A Go template expression that must evaluate to a "truthy" value. |
    | `fail_message`| string | No | A custom message to include in the fatal error if the assertion fails. |
*   **Return Values / Summary:** `{ "condition_met": true, "evaluated_value": any }` on success.
*   **Examples:**
    ```yaml
    process:
      module: control:assert
      params:
        condition: '{{ .http_response.status_code == 200 }}'
        fail_message: "API call did not return HTTP 200 OK."
    ```

### `control:identity`
*   **Synopsis:** A no-op module that passes its parameters through as its summary.
*   **Description:** This simple utility module performs no action other than returning its received `params` map as its `summary` result. It is invaluable for creating structured variables in the state, transforming data structures declaratively, and for debugging playbook logic by inspecting the state at a certain point.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:** Any valid map.
*   **Return Values / Summary:** The exact map provided in the `params`.
*   **Examples:**
    ```yaml
    # Create a structured 'user' object in the state
    process:
      module: control:identity
      params:
        name: "jdoe"
        uid: 1001
        groups: ["users", "docker"]
    register: new_user_data
    ```

---

## **Layer 2: Connection Layer**

**Analogy:** The "Physical Wires" and "Ports."
**Purpose:** Establishes and manages raw, uninterpreted network connections. This provides the foundation for all higher-level protocols and enables powerful, low-level network testing and automation. Connections are stateful resources managed by the GXO Kernel and are referenced by a temporary `connection_id` handle.

### `connection:open`
*   **Synopsis:** Establishes an outbound TCP or UDP connection.
*   **Description:** This is a low-level primitive for network automation and testing. It opens a socket to a specified network address and registers it with the GXO engine's internal connection manager, returning a unique `connection_id`. This ID must be passed to subsequent `connection:write`, `connection:read`, and `connection:close` workloads to interact with the persistent connection.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Choices | Description |
    |---|---|---|---|---|
    | `network` | string | Yes | `tcp`, `udp` | The network protocol to use. |
    | `address` | string | Yes | | The network address to connect to, in `"host:port"` format. |
    | `timeout` | string | No | | Connection timeout (e.g., `"5s"`). Defaults to the OS default. |
*   **Return Values / Summary:**
    | Key | Type | Description |
    |---|---|---|
    | `connection_id` | string | The unique handle for this connection, used by other `connection:*` modules. |
    | `local_addr` | string | The local address and port of the established socket. |
    | `remote_addr` | string | The remote address and port of the established socket. |
*   **Examples:**
    ```yaml
    process:
      module: connection:open
      params:
        network: "tcp"
        address: "example.com:80"
    register: http_conn
    ```

### `connection:listen`
*   **Synopsis:** Listens on a port for incoming connections.
*   **Description:** This is the entry point for creating any kind of server in GXO. It binds to a local port and listens for incoming connections. When a new client connects, this module emits a new record onto its output stream. Each record contains a unique `connection_id` handle for the new connection, which can then be consumed by an `event_driven` workload to handle the client's session.
*   **Supported Lifecycles:** `supervise`, `event_driven`
*   **Parameters:**
    | Name | Type | Required? | Choices | Description |
    |---|---|---|---|---|
    | `network` | string | Yes | `tcp`, `udp` | The network protocol to listen on. |
    | `address` | string | Yes | | The local network address to bind to, in `"host:port"` format (e.g., `":8080"`). |
*   **Output Stream:** A stream of records, each containing `{ "connection_id": string, "remote_addr": string }` for an accepted connection.

### `connection:read`
*   **Synopsis:** Reads data from an open connection handle.
*   **Description:** Reads raw data from an open socket identified by a `connection_id`. It offers several modes: reading a fixed number of bytes, reading until a specific delimiter string is found, or reading until the connection is closed by the remote peer. The read data can be returned as a UTF-8 string or as Base64/Hex for binary protocols.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Default | Description |
    |---|---|---|---|---|
    | `connection_id`| string | Yes | | The ID returned by `connection:open` or `connection:listen`. |
    | `read_bytes` | int | No | | Read exactly this many bytes. If `read_until` is also set, it reads until the first condition is met. |
    | `read_until` | string | No | | Read until this delimiter string is encountered. The delimiter is included in the result. |
    | `timeout` | string | No | | Read timeout (e.g., `"10s"`). Fails the task if no data is received within this period. |
    | `encoding` | string | No | `"string"` | How to encode the read binary data in the summary. Choices: `"string"`, `"base64"`, `"hex"`. |
*   **Return Values / Summary:** `{ "data": string, "bytes_read": int }`

### `connection:write`
*   **Synopsis:** Writes raw data to an open connection handle.
*   **Description:** Allows for sending precisely crafted data over a network socket, enabling low-level protocol testing, fuzzing, or interaction with non-HTTP services. Data can be provided as a standard UTF-8 string or as Base64/Hex for sending arbitrary binary data.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Default | Description |
    |---|---|---|---|---|
    | `connection_id`| string | Yes | | The ID of the connection to write to. |
    | `data` | string | Yes | | The data to write to the socket. |
    | `encoding` | string | No | `"string"` | The encoding of the `data` field. Choices: `"string"`, `"base64"`, `"hex"`. |
*   **Return Values / Summary:** `{ "bytes_written": int }`

### `connection:close`
*   **Synopsis:** Closes an open network connection handle.
*   **Description:** Gracefully closes a persistent connection that was opened by `connection:open` or `connection:listen` and releases its resources within the GXO engine.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `connection_id`| string | Yes | The ID of the connection to close. |
*   **Return Values / Summary:** `{ "connection_id": string, "closed": true }`

---

## **Layer 3: Protocol Layer**

**Analogy:** The "Rules of the Road."
**Purpose:** Implements specific application-layer protocols on top of the raw connections provided by the Connection Layer. This is where the logic for understanding HTTP, DNS, SSH, etc., resides.

### `dns:query`
*   **Synopsis:** Performs standard DNS lookups.
*   **Description:** Resolves a domain name to its corresponding records (e.g., A, AAAA, CNAME, MX, TXT). Useful for network diagnostics and service discovery before making connections.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Default | Description |
    |---|---|---|---|---|
    | `name` | string | Yes | | The hostname or domain name to query. |
    | `type` | string | No | `"A"` | The DNS record type to query. |
*   **Return Values / Summary:** `{ "answers": list[string] }` containing the resolved records.

### `http:listen`
*   **Synopsis:** A primitive HTTP server that parses requests.
*   **Description:** A core GXO web server component. It consumes a stream of connection IDs from `connection:listen`, reads the raw TCP stream, and parses it according to the HTTP/1.1 protocol. For each valid HTTP request found, it emits a structured record onto its output stream. This record contains a `request_id` handle that must be used by `http:respond` to send a reply. This module separates network handling from application logic.
*   **Supported Lifecycles:** `supervise`, `event_driven`
*   **Streams:** Requires one `stream_input` from a `connection:listen` workload.
*   **Output Stream:** A stream of records, each representing an HTTP request: `{ "request_id": string, "method": string, "path": string, "headers": map, "body": string, "query_params": map }`.

### `http:respond`
*   **Synopsis:** Sends an HTTP response for a request handled by `http:listen`.
*   **Description:** Completes the server-side HTTP lifecycle. It takes a `request_id` from an `http:listen` event and sends a fully-formed HTTP response back to the original client over the correct socket, which is managed internally by the engine.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Default | Description |
    |---|---|---|---|---|
    | `request_id` | string | Yes | | The handle from the `http:listen` event record. |
    | `status_code`| int | No | `200` | The HTTP status code for the response. |
    | `headers` | map | No | | A map of HTTP headers to include in the response. |
    | `body` | string | No | | The response body. |
*   **Return Values / Summary:** `{ "request_id": string, "bytes_written": int }`

### `ssh:connect`
*   **Synopsis:** Establishes an SSH connection and returns a handle.
*   **Description:** Creates a persistent, authenticated SSH connection to a remote host. It returns a `connection_id` handle for use with other `ssh:*` modules. Authentication details must be provided.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `host` | string | Yes | The remote host's address. |
    | `port` | int | No | The SSH port on the remote host. Defaults to `22`. |
    | `user` | string | Yes | The username to connect with. |
    | `password` | string | No | The user's password. `password` or `private_key` is required. Use `{{ secret '...' }}`. |
    | `private_key`| string | No | The SSH private key content (not path). Use `{{ secret '...' }}`. |
*   **Return Values / Summary:** `{ "connection_id": string, "host": string, "user": string }`

### `ssh:command`
*   **Synopsis:** Executes a single command over an established SSH connection.
*   **Description:** Runs a non-interactive shell command on a remote host using a previously established SSH connection handle. It captures stdout, stderr, and the exit code.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `connection_id`| string | Yes | The handle from `ssh:connect`. |
    | `command` | string | Yes | The shell command to execute on the remote host. |
*   **Return Values / Summary:** `{ "stdout": string, "stderr": string, "exit_code": int }`

### `ssh:script`
*   **Synopsis:** Executes a local script on a remote host via SSH.
*   **Description:** Transfers a script file from the local `Workspace` to a temporary location on the remote host, makes it executable, runs it, and then cleans it up. This is useful for executing complex logic without relying on long, multi-line `command` strings.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `connection_id`| string | Yes | The handle from `ssh:connect`. |
    | `script_path` | string | Yes | The path to the local script file within the `Workspace`. |
    | `script_args` | list[string] | No | Optional arguments to pass to the remote script. |
*   **Return Values / Summary:** `{ "stdout": string, "stderr": string, "exit_code": int }`

---

## **Layer 4: Data Plane**

**Analogy:** The "Presentation Layer" or "ETL Engine."
**Purpose:** This layer contains a complete, streaming-first toolkit for parsing, transforming, filtering, joining, and aggregating data. These modules are the workhorses of any data-intensive GXO pipeline.

### `data:parse`
*   **Synopsis:** A unified parser that converts raw data into a stream of structured records.
*   **Description:** This is a primary generator module. It takes a block of text (`content`) and a `format` specifier, and produces a stream of structured records. It's the main entry point for getting data from files or API responses into a GXO pipeline.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Choices | Description |
    |---|---|---|---|---|
    | `content` | string | Yes | | The raw string content to parse. |
    | `format` | string | Yes | `json`, `yaml`, `csv`, `xml`, `text_lines`, `regex` | The format of the `content`. |
    | `format_options`| map | No | | A map of options specific to the chosen format (e.g., `json_path` for JSON, `delimiter` for CSV, `capture_groups` for regex). |
*   **Output Stream:** A stream of structured `map[string]interface{}` records.

### `data:map`
*   **Synopsis:** Transforms each record in a stream using a template.
*   **Description:** This module consumes a stream and applies a Go template to each record. The output of the template becomes the new record sent to the output stream. It can be used to reshape data, add/remove fields, or perform calculations. If the template returns a JSON string, `data:map` will automatically unmarshal it back into a map object.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `template` | string | Yes | The Go template to apply to each record. The record's fields are available as top-level variables. |
*   **Streams:** Requires one `stream_input`. Produces one output stream.

### `data:filter`
*   **Synopsis:** Discards records from a stream based on a condition.
*   **Description:** Consumes a stream and evaluates a `condition` template for each record. If the condition is "truthy", the original record is passed through to the output stream. If "falsy", the record is dropped.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `condition` | string | Yes | A Go template expression that evaluates to true or false for each record. |
*   **Streams:** Requires one `stream_input`. Produces one output stream.

### `data:join`
*   **Synopsis:** Performs a SQL-like join on multiple input streams.
*   **Description:** A powerful stateful streaming module that implements a two-phase hash join. It designates one or more streams as the "build" side, which it reads entirely into memory. It then reads the "probe" stream and, for each record, finds matches in the in-memory build table based on the join key.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Choices | Description |
    |---|---|---|---|---|
    | `join_type` | string | Yes | `inner`, `left`, `right`, `outer` | The type of join to perform. |
    | `on` | list[map] | Yes | | A list of maps, one for each input stream, specifying its `stream` name, `role` (`build` or `probe`), and join key (`field` or `template`). |
    | `output`| map | No | | A map specifying the output format (`merge_strategy`, `nesting_keys`). |
    | `limits`| map | No | | A map for performance tuning, e.g., `max_build_records`. |
*   **Streams:** Requires multiple `stream_inputs`. Produces one output stream of joined records.

### `data:aggregate`
*   **Synopsis:** Groups and aggregates records from a stream over time or count.
*   **Description:** A stateful streaming module that collects records and computes aggregations (like `count`, `sum`, `avg`, `min`, `max`) over them. Records can be grouped by specified fields and emitted based on a tumbling `window` of time or a fixed record `count`.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Description |
    |---|---|---|---|
    | `group_by_fields` | list[string] | No | The fields to group records by. |
    | `aggregate_fields`| list[map] | Yes | A list of maps, each defining an aggregation: `{ "name": "output_field", "op": "count|sum|avg", "source_field": "input_field" }`. |
    | `window` | string | No | A time duration string (e.g., "5m") for a tumbling time window. Either `window` or `count` is required. |
    | `count` | int | No | A record count for a tumbling count window. |
*   **Streams:** Requires one `stream_input`. Produces one output stream of aggregated records.

### `data:format`
*   **Synopsis:** A unified formatter that consumes a stream and produces a single string.
*   **Description:** This is a primary sink module. It consumes an entire input stream and formats the collection of records into a single string `summary`. This is used to convert processed data back into a standard format like JSON or CSV for writing to a file or sending in an API call.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:**
    | Name | Type | Required? | Choices | Description |
    |---|---|---|---|---|
    | `format` | string | Yes | `json`, `yaml`, `csv`, `text` | The output format. |
    | `format_options`| map | No | | Options specific to the format (e.g., `headers` for CSV, a `template` for text). |
*   **Return Values / Summary:** `{ "formatted_content": string }`
*   **Streams:** Requires one `stream_input`. Produces no output stream.

### `passthrough`
*   **Synopsis:** A fundamental streaming utility that forwards all records from inputs to outputs.
*   **Description:** This module is the simplest possible streaming transformer. It reads every record from all of its input streams and writes each record, unmodified, to all of its output streams. It is essential for building complex pipeline topologies and implementing fan-in/fan-out patterns.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:** None.
*   **Streams:** Requires `stream_inputs`. Produces an output stream.
*   **Return Values / Summary:** `{ "records_processed": int }`

---

*(Note: The following layers represent future development and are included here to complete the GXO-AM vision.)*

## **Layer 5: Application Layer**

**Analogy:** The "User-Facing Application."
**Purpose:** Provides high-level, convenient modules for interacting with common services, built by composing primitives from the lower layers.

### `http:request`
*   **Synopsis:** The universal, all-in-one client for any HTTP-based API.
*   **Description:** This is a high-level module that handles its own connection management, authentication, and complex logic like pagination internally. It is the primary tool for interacting with most web services (REST, SOAP, etc.). It supports detailed configuration for headers, timeouts, TLS verification, and can automatically parse JSON or XML responses.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:** `url`, `method`, `headers`, `body`, `timeout`, `skip_tls_verify`, `auth` (auth block), `cookie_jar` (bool), `pagination` (map), `success_when` (template), `fail_when` (template).
*   **Return Values / Summary:** `{ "status_code": 200, "headers": map, "body": string, "json_body": any, "xml_body": any, "latency_ms": int }`

### `database:query`
*   **Synopsis:** Executes a SQL query against a supported database.
*   **Description:** Provides a unified interface for executing SQL queries. It manages the connection pool based on a connection profile. For `SELECT` queries, it produces a stream of records, where each record represents a row from the result set. For `INSERT`, `UPDATE`, `DELETE`, it returns a summary of rows affected.
*   **Supported Lifecycles:** `run_once`
*   **Parameters:** `connection_profile` (reference to a configured profile), `query` (string), `query_params` (list).
*   **Output Stream:** For `SELECT`, a stream of row records. Otherwise, no output stream.
*   **Return Values / Summary:** For non-SELECT, `{ "rows_affected": int }`.

---

## **Layer 6: Integration Layer**

**Analogy:** The "Ecosystem."
**Purpose:** Provides first-class, intelligent, and opinionated wrappers for specific external tools and platforms, simplifying common cross-tool workflows.

### `artifact:*` Suite
*   **Synopsis:** Manages build artifacts in a GXO-native way.
*   **Description:** This suite provides a GXO-specific abstraction for artifact management. It is built on top of the Layer 5 `object_storage` modules but understands GXO concepts like the `Workspace`.
*   **Modules:**
    *   **`artifact:upload`** (`run_once`): Takes a local path from the `Workspace` and a logical artifact name. It uploads the file to a configured blob store and returns a structured **Artifact Handle** (a versioned, checksummed reference) in its `summary`.
    *   **`artifact:download`** (`run_once`): Takes an Artifact Handle from state and downloads the corresponding file into the current `Workspace`.

### `terraform:run`
*   **Synopsis:** An intelligent wrapper for the Terraform CLI.
*   **Description:** Executes `terraform apply`, `plan`, or `destroy`. It runs within the `Workspace` and is designed to automatically parse the `terraform output -json` command after a successful `apply` and register the outputs directly into the GXO state, closing the state gap between IaC and subsequent configuration.
*   **Supported Lifecycles:** `run_once`

### Notification Suite (`slack:post_message`, `email:send`, etc.)
*   **Synopsis:** A suite of modules for sending notifications to common platforms.
*   **Description:** These modules provide convenient, high-level wrappers around the `http:request` module for specific services like Slack, PagerDuty, or sending email via an SMTP gateway. They simplify the process by providing platform-specific parameters (e.g., `channel` for Slack) instead of requiring the user to construct the full API request.
*   **Supported Lifecycles:** `run_once`

Excellent. I understand completely. The previous document established the *depth* and *style* of the documentation. This appendix will now provide the *breadth*â€”an exhaustive, high-level outline of the complete GXO Standard Library (GXO-SL), ensuring all capabilities we've discussed are accounted for.

This appendix will serve as the master checklist for module development, organized by the GXO Automation Model (GXO-AM) layers.

Here is the new appendix for the `GXO-SL.md` document.

---

## **Appendix A: GXO-SL Complete Module Checklist**

This appendix provides a comprehensive, high-level checklist of all modules planned for the GXO Standard Library (GXO-SL) Version 1.0. It is organized by the GXO Automation Model (GXO-AM) layers and serves as the master scope for module development.

### **Layer 1: System Layer**
*Purpose: Host OS and Kernel control primitives.*

*   **`exec`**: Execute local system commands.
*   **`filesystem:read`**: Read file content.
*   **`filesystem:write`**: Write content to a file.
*   **`filesystem:stat`**: Get file/directory metadata.
*   **`filesystem:list`**: Stream the contents of a directory.
*   **`filesystem:manage`**: Idempotently manage file/directory state (presence, permissions, ownership).
*   **`control:wait_for_signal`**: Pause a workflow for external resumption.
*   **`control:barrier`**: Synchronize multiple streams for pipeline staging.
*   **`control:assert`**: Fail a workload based on a condition.
*   **`control:identity`**: Pass-through parameters as a summary for state structuring.

### **Layer 2: Connection Layer**
*Purpose: Raw, uninterpreted network socket management.*

*   **`connection:open`**: Establish an outbound TCP/UDP connection.
*   **`connection:listen`**: Listen for inbound TCP/UDP connections and stream connection handles.
*   **`connection:read`**: Read raw bytes from a connection handle.
*   **`connection:write`**: Write raw bytes to a connection handle.
*   **`connection:close`**: Close a managed connection.

### **Layer 3: Protocol Layer**
*Purpose: Implementation of specific network protocols.*

*   **`dns:query`**: Perform DNS lookups (A, AAAA, MX, TXT, CNAME, etc.).
*   **`http:listen`**: HTTP/1.1 server primitive; consumes connection handles and produces a stream of HTTP request handles.
*   **`http:respond`**: Sends an HTTP response for a given request handle.
*   **`ssh:connect`**: Establish an SSH connection and return a handle.
*   **`ssh:command`**: Execute a single command over an SSH connection.
*   **`ssh:script`**: Transfer and execute a local script on a remote host via SSH.
*   **`ssh:upload`**: Upload a file to a remote host via SCP/SFTP.
*   **`ssh:download`**: Download a file from a remote host via SCP/SFTP.

### **Layer 4: Data Plane (ETL Services)**
*Purpose: The complete, streaming-first toolkit for data transformation.*

*   **`passthrough`**: Fundamental streaming utility for fan-in/fan-out and pipeline construction.
*   **`data:generate_from_list`**: Generate a stream from a static list.
*   **`data:parse`**: Unified parser.
    *   Formats: `json`, `yaml`, `csv`, `xml`, `text_lines`, `regex`, `logfmt`, `grok`, `xlsx`.
*   **`data:map`**: Transform records in a stream using a template.
*   **`data:filter`**: Filter a stream based on a condition.
*   **`data:join`**: Perform SQL-like joins on multiple streams.
*   **`data:aggregate`**: Group and aggregate records (time or count windows).
*   **`data:format`**: Unified formatter. Consumes a stream to produce a single string `summary`.
    *   Formats: `json`, `yaml`, `csv`, `text` (template-based), `html_table`.

### **Layer 5: Application Layer**
*Purpose: High-level, convenient clients for common services.*

*   **`http:request`**: The universal HTTP client.
    *   Features: REST (JSON), SOAP (XML), file uploads/downloads, authentication helpers (Basic, Bearer, OAuth2), cookie management, advanced pagination logic.
*   **`database:query`**: Execute SQL queries.
    *   Drivers: PostgreSQL, MySQL, SQLite, MSSQL, Oracle.
*   **`template:render`**: Render a Go template string with variables.
*   **`object_storage:get_object`**: Retrieve an object from a blob store.
*   **`object_storage:put_object`**: Upload content to an object in a blob store.
*   **`object_storage:list_objects`**: Stream object metadata from a blob store.
*   **`object_storage:delete_object`**: Delete an object from a blob store.
*   **`object_storage:manage_bucket`**: Idempotently manage bucket state (presence, ACLs).
*   **`crypto:generate_key`**: Generate cryptographic keys (AES, RSA, ED25519).
*   **`crypto:encrypt`**: Encrypt data with a symmetric key (AES-GCM).
*   **`crypto:decrypt`**: Decrypt data with a symmetric key.
*   **`vault:encrypt`**: `ansible-vault` compatible data-at-rest encryption.
*   **`vault:decrypt`**: `ansible-vault` compatible data-at-rest decryption.

### **Layer 6: Integration Layer**
*Purpose: Opinionated, intelligent wrappers for external tools and platforms.*

*   **Artifact Management:**
    *   **`artifact:upload`**: Upload a file/directory from the `Workspace` to a configured blob store, returning a versioned, checksummed Artifact Handle.
    *   **`artifact:download`**: Download an artifact using its Handle into the `Workspace`.
*   **IaC / Config Management:**
    *   **`terraform:run`**: Intelligent wrapper for Terraform CLI; automatically captures outputs into GXO state.
    *   **`ansible:playbook`**: Executes an Ansible playbook, bridging GXO's state into Ansible's inventory and variables.
    *   **`docker:run`**: Runs a Docker container as an ephemeral process.
    *   **`docker:build`**: Builds a Docker image from a Dockerfile.
    *   **`docker:push`**: Pushes a Docker image to a registry.
*   **Secrets Management:**
    *   **`vault:read`**: Read a secret from a HashiCorp Vault path.
    *   **`vault:write`**: Write a secret to a HashiCorp Vault path.
    *   **`aws_secretsmanager:read`**: Read a secret from AWS Secrets Manager.
    *   **`gcp_secretmanager:read`**: Read a secret from GCP Secret Manager.
*   **Notification & Communication:**
    *   **`slack:post_message`**: Post a message to a Slack channel.
    *   **`email:send`**: Send an email via an SMTP gateway.
    *   **`pagerduty:trigger_event`**: Trigger a PagerDuty incident.
*   **Cloud Services (High-Level Wrappers):**
    *   **`aws:s3_sync`**: Synchronize a local directory with an S3 bucket.
    *   **`aws:ec2_instance`**: Idempotently manage the state of an EC2 instance.
    *   **`gcp:gcs_sync`**: Synchronize a local directory with a GCS bucket.
    *   **`gcp:gce_instance`**: Idempotently manage the state of a GCE instance.
    *   **`azure:blob_sync`**: Synchronize a local directory with an Azure Blob container.
    *   **`azure:vm_instance`**: Idempotently manage the state of an Azure VM.

